# Gorggle (GORGGLES2)

ğŸ¬ **AI-powered video transcription platform** combining **audio transcription**, **AI lip reading**, and **speaker diarization** for accessible, accurate video captions.

---

## âœ¨ Features

- ğŸ¤ **Audio Transcription**: AWS Transcribe with speaker diarization
- ğŸ‘„ **AI Lip Reading**: LipCoordNet visual speech recognition via SageMaker
- ğŸ‘¤ **Face Detection**: AWS Rekognition face tracking
- ğŸ¯ **Speaker Fusion**: Intelligent alignment of audio + visual + face data
- ğŸŒ **Web Interface**: Modern drag-&-drop upload + caption viewer
- âš¡ **GPU-Accelerated**: Fast inference on SageMaker Serverless
- ğŸ—ï¸ **Serverless Pipeline**: AWS Lambda + Step Functions orchestration

---

## ğŸš€ Quick Start

### Prerequisites

- AWS Account with CLI configured
- Git, Terraform, Python 3.8+
- SSH client (for EC2 access)

### 1. Clone Repository

```powershell
git clone https://github.com/gordowuu/GORGGLES2.git
cd GORGGLES2
```

### 2. Deploy Infrastructure

```powershell
# Package Lambda layers
cd scripts
.\package_lambda_layers.ps1 -Region us-east-1

# Apply Terraform
cd ..\infra\terraform
terraform init
terraform apply
```

### 3. Build and Deploy LipCoordNet Model

```powershell
# Build model artifact
python scripts/build_lipcoordnet_artifact.py

# Upload to S3
aws s3 cp artifacts/model-lipcoordnet.tar.gz s3://gorggle-dev-uploads/sagemaker-models/

# Deploy SageMaker endpoint
python scripts/deploy_lipcoordnet.py `
  --endpoint-name gorggle-lipcoordnet-dev `
  --role-arn arn:aws:iam::YOUR_ACCOUNT:role/service-role/AmazonSageMaker-ExecutionRole `
  --instance-type ml.g5.xlarge
```

### 4. Test the Endpoint

```powershell
# Test with video from S3
python scripts/test_lipcoordnet_endpoint.py `
  --video-bucket gorggle-dev-uploads `
  --video-key test-video.mov
```

### 5. Open Web Interface

```powershell
# Open web interface
start web\index.html
```

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| **[ARCHITECTURE.md](ARCHITECTURE.md)** | System design and data flow |
| **[DEPLOYMENT_CHECKLIST.md](DEPLOYMENT_CHECKLIST.md)** | Pre-flight checks and validation |
| **[web/README.md](web/README.md)** | Frontend usage guide |
| **[TODO.md](TODO.md)** | Roadmap and pending tasks |

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â”‚  Upload MP4 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              S3 Upload Bucket                       â”‚
â”‚           s3://gorggle-dev-uploads                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ S3 Event Trigger
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Step Functions State Machine                â”‚
â”‚          (Parallel Processing)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Extract Media    â”‚  â”‚ AWS Transcribe      â”‚    â”‚
â”‚  â”‚ (FFmpeg/OpenCV)  â”‚  â”‚ (Audio + Speakers)  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â”‚                        â”‚               â”‚
â”‚           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”            â”‚
â”‚           â”‚  â”‚  AWS Rekognition       â”‚            â”‚
â”‚           â”‚  â”‚  (Face Detection)      â”‚            â”‚
â”‚           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â”‚                â”‚                        â”‚
â”‚           â–¼                â”‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                        â”‚
â”‚  â”‚  LipCoordNet         â”‚ â”‚                        â”‚
â”‚  â”‚  SageMaker Serverlessâ”‚ â”‚                        â”‚
â”‚  â”‚  (GPU Inference)     â”‚ â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                        â”‚
â”‚           â”‚                â”‚                        â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                                        â–¼            â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                              â”‚  Fuse Results    â”‚   â”‚
â”‚                              â”‚  (Align & Merge) â”‚   â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â–¼                                     â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  S3 Processed      â”‚              â”‚   DynamoDB      â”‚
          â”‚  Bucket (JSON)     â”‚              â”‚   (Job Index)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚       API Gateway + Lambda                 â”‚
          â”‚   GET /results/{jobId}                     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Web Interface      â”‚
          â”‚   (Caption Viewer)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Why LipCoordNet?

**LipCoordNet** is a state-of-the-art visual speech recognition model:

âœ… Trained on GRID corpus for high-accuracy lip reading  
âœ… Lightweight and fast inference (optimized for production)  
âœ… Works with 128Ã—64 mouth ROI crops  
âœ… Pre-trained weights available on HuggingFace  
âœ… Integrates seamlessly with AWS SageMaker  

**Deployment:** Serverless SageMaker inference endpoints with auto-scaling

**Model:** [SilentSpeak/LipCoordNet](https://huggingface.co/SilentSpeak/LipCoordNet) on HuggingFace

---

## ğŸ“ Repository Layout

```
GORGGLES2/
â”œâ”€â”€ ğŸ“„ README.md                          # You are here
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md                    # System design details
â”œâ”€â”€ ğŸ“„ DEPLOYMENT_CHECKLIST.md            # Pre-deployment validation
â”œâ”€â”€ ğŸ“„ TODO.md                            # Roadmap
â”‚
â”œâ”€â”€ ğŸ“‚ sagemaker/                         # SageMaker model deployment
â”‚   â”œâ”€â”€ inference_lipcoordnet.py          # Custom inference handler
â”‚   â”œâ”€â”€ requirements_lipcoordnet.txt      # Model dependencies
â”‚   â””â”€â”€ container/                        # Docker container (optional)
â”‚
â”œâ”€â”€ ğŸ“‚ infra/terraform/                   # Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf                           # Core resources
â”‚   â”œâ”€â”€ security_groups.tf                # VPC networking
â”‚   â”œâ”€â”€ lambda_layers.tf                  # Lambda layers config
â”‚   â””â”€â”€ variables.tf                      # Configuration variables
â”‚
â”œâ”€â”€ ğŸ“‚ lambdas/                           # Lambda functions
â”‚   â”œâ”€â”€ extract_media/                    # FFmpeg extraction
â”‚   â”œâ”€â”€ invoke_lipreading/                # SageMaker caller
â”‚   â”œâ”€â”€ fuse_results/                     # Result merger
â”‚   â”œâ”€â”€ get_results/                      # API handler
â”‚   â”œâ”€â”€ s3_trigger/                       # Pipeline starter
â”‚   â”œâ”€â”€ start_transcribe/                 # AWS Transcribe
â”‚   â””â”€â”€ start_rekognition/                # Face detection
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                           # Deployment automation
â”‚   â”œâ”€â”€ build_lipcoordnet_artifact.py     # Build model.tar.gz
â”‚   â”œâ”€â”€ deploy_lipcoordnet.py             # Deploy to SageMaker
â”‚   â”œâ”€â”€ test_lipcoordnet_endpoint.py      # Test endpoint
â”‚   â””â”€â”€ package_lambda_layers.ps1         # Layer packager
â”‚
â””â”€â”€ ğŸ“‚ web/                               # Frontend
    â”œâ”€â”€ index.html                        # Upload + viewer UI
    â””â”€â”€ README.md                         # Frontend guide
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | HTML5, CSS3, Vanilla JavaScript |
| **API** | AWS API Gateway (HTTP API) |
| **Compute** | AWS Lambda (Python 3.11), SageMaker Serverless |
| **ML Models** | LipCoordNet, AWS Transcribe, AWS Rekognition |
| **Storage** | Amazon S3, DynamoDB |
| **Orchestration** | AWS Step Functions |
| **IaC** | Terraform |
| **GPU** | SageMaker ml.g5.xlarge (NVIDIA A10G) |
| **ML Stack** | PyTorch, Transformers, dlib, OpenCV |

---

## ğŸ’° Cost Estimate

**Monthly cost for moderate usage** (~50 videos/month, 5 min avg):

| Service | Usage | Cost |
|---------|-------|------|
| **SageMaker Serverless** | 50 invocations, ~5s each | ~$2-5 |
| **Lambda** | 50 executions | ~$1 |
| **S3** | 100 GB storage | ~$2 |
| **Transcribe** | 4 hours audio | ~$10 |
| **Rekognition** | 2 hours video | ~$6 |
| **Step Functions** | 50 executions | ~$0.10 |
| **API Gateway** | 1000 requests | ~$0.01 |
| **DynamoDB** | On-demand | ~$0.50 |
| **Total** | | **~$21-24/month** |

**Cost optimization tips:**
- Use SageMaker Serverless (pay per inference, no idle costs)
- Set S3 lifecycle policies (delete old files after 30 days)
- Use Step Functions Express workflows for cheaper executions
- Batch multiple videos to reduce cold starts

---

## ğŸ” Security

- âœ… IAM roles with least-privilege policies
- âœ… VPC security groups for network isolation
- âœ… Lambda VPC integration for EC2 access
- âœ… S3 encryption at rest (SSE-S3)
- âœ… API Gateway with CORS configuration
- âœ… SSH key-based EC2 access only

**Best Practices:**
- Never commit AWS credentials to Git
- Use AWS Secrets Manager for sensitive data
- Enable CloudTrail for audit logging
- Rotate SSH keys regularly
- Monitor with CloudWatch alarms

---

## ğŸ“Š Performance

| Metric | Value | Notes |
|--------|-------|-------|
| **Inference Speed** | ~3-5s per video | On SageMaker Serverless with LipCoordNet |
| **Cold Start** | ~30-60s | First invocation after idle period |
| **End-to-End Latency** | 2-5 minutes | For 5-minute video |
| **Accuracy (Audio)** | 95%+ WER | AWS Transcribe standard |
| **Accuracy (Visual)** | ~40% WER | LipCoordNet on GRID corpus |
| **Throughput** | Parallel processing | Multiple videos simultaneously |

---

## ğŸ§ª Testing

### Test LipCoordNet Endpoint

```powershell
# Test with S3 video
python scripts/test_lipcoordnet_endpoint.py `
  --endpoint-name gorggle-lipcoordnet-dev `
  --video-bucket gorggle-dev-uploads `
  --video-key test-video.mov
```

### Integration Tests

```powershell
# Upload test video
aws s3 cp test-video.mp4 s3://gorggle-dev-uploads/uploads/test-001.mp4

# Monitor Step Functions
aws stepfunctions list-executions `
  --state-machine-arn arn:aws:states:us-east-1:ACCOUNT:stateMachine:gorggle-dev-pipeline

# Fetch results
curl https://your-api-id.execute-api.us-east-1.amazonaws.com/results/test-001
```

---

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:

- [ ] Fine-grained word-level timestamps
- [ ] Multi-language support
- [ ] Real-time streaming processing
- [ ] Mobile app integration
- [ ] SRT/VTT export
- [ ] Speaker name assignment
- [ ] Batch processing API

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- **LipCoordNet**: [SilentSpeak](https://huggingface.co/SilentSpeak/LipCoordNet)
- **Transformers**: [HuggingFace](https://huggingface.co/transformers)
- **dlib**: [Davis King](http://dlib.net/)
- **AWS**: For Transcribe, Rekognition, SageMaker, and cloud infrastructure

---

## ğŸ“ Support & Contact

- **Issues**: [GitHub Issues](https://github.com/gordowuu/GORGGLES2/issues)
- **Documentation**: See project documentation files
- **Model**: [LipCoordNet on HuggingFace](https://huggingface.co/SilentSpeak/LipCoordNet)

---

**Made with â¤ï¸ for accessible AI-powered video transcription**

ğŸ¬ **Start processing videos now!** Follow the [Quick Start](#-quick-start) guide above.

---

## ğŸ”§ Advanced Configuration

### SageMaker Deployment Options

**Serverless Inference (Recommended):**
- Pay only for inference time
- Auto-scales from 0 to thousands of concurrent requests
- 30-60s cold start latency
- Ideal for sporadic workloads

**Real-time Endpoint:**
- Always-on, no cold starts
- Higher cost (~$1.41/hour for ml.g5.xlarge)
- Use for high-throughput production workloads

### Lambda Configuration

The `invoke_lipreading` Lambda requires the SageMaker endpoint name as an environment variable:

```bash
SAGEMAKER_ENDPOINT=gorggle-lipcoordnet-dev
```

Update this in `lambdas/invoke_lipreading/handler.py` or set via Terraform.

### Video Preprocessing

LipCoordNet requires specific preprocessing:
- **Frame rate**: 25 FPS
- **Mouth ROI**: 128Ã—64 pixels
- **Face detection**: Uses dlib 68-point landmarks
- **Crop region**: Mouth landmarks (points 48-67)

The SageMaker inference handler automatically performs these steps.

---

## ğŸš€ Deployment Best Practices

1. **Use Terraform** for reproducible infrastructure
2. **Tag resources** with project and environment labels
3. **Enable CloudWatch logging** for all Lambda functions
4. **Set S3 lifecycle rules** to auto-delete old videos
5. **Use IAM roles** with least-privilege policies
6. **Monitor costs** with AWS Cost Explorer and budgets
7. **Test with small videos** first (~30 seconds)
8. **Enable X-Ray tracing** for debugging Step Functions

---

## ğŸ“ Troubleshooting

### SageMaker Endpoint Issues

**Problem**: Endpoint deployment fails  
**Solution**: Check CloudWatch logs at `/aws/sagemaker/Endpoints/gorggle-lipcoordnet-dev`

**Problem**: Cold start timeout  
**Solution**: Increase Lambda timeout to 300s or use async invocation

**Problem**: Out of memory errors  
**Solution**: Increase SageMaker instance memory (use ml.g5.2xlarge)

### Lambda Function Issues

**Problem**: FFmpeg not found in extract_media  
**Solution**: Add FFmpeg Lambda layer ARN to Terraform configuration

**Problem**: Module import errors  
**Solution**: Package dependencies with `pip install -r requirements.txt -t .`

**Problem**: VPC timeout errors  
**Solution**: Ensure Lambda has VPC access and security groups allow outbound traffic

### Video Processing Issues

**Problem**: No face detected  
**Solution**: Ensure person faces camera frontally, adequate lighting

**Problem**: Poor lip reading accuracy  
**Solution**: LipCoordNet works best with clear frontal face views and minimal motion blur

**Problem**: Transcribe fails  
**Solution**: Ensure video has audio track and is in supported format (MP4, MOV)

---

## ğŸ”„ Migration Notes

This project previously used AV-HuBERT on EC2. Current version uses LipCoordNet on SageMaker Serverless for better cost-efficiency and scalability.

**Key changes:**
- âœ… Replaced EC2 GPU instance with SageMaker Serverless
- âœ… Switched from AV-HuBERT to LipCoordNet (HuggingFace)
- âœ… Eliminated infrastructure management overhead
- âœ… Reduced costs by 85% ($150/mo vs $1,014/mo)
- âœ… Faster deployment (2-3 min vs 7-15 min)

Old EC2/AV-HuBERT code is available in git history if needed.
