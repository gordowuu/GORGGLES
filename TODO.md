# What You Need To Do - AV-HuBERT Deployment Checklist

## ‚úÖ What's Done (Already Completed)

- ‚úÖ AV-HuBERT server implementation with proper mouth ROI extraction
- ‚úÖ Face detection and landmark detection using dlib
- ‚úÖ 96x96 mouth crop preprocessing (official AV-HuBERT requirement)
- ‚úÖ Automated EC2 setup script (`setup_ec2.sh`)
- ‚úÖ Model download script (`download_models.sh`)
- ‚úÖ Comprehensive documentation (README, QUICKSTART, ARCHITECTURE)
- ‚úÖ All code pushed to GitHub: https://github.com/gordowuu/GORGGLES2

## üìã Your Action Items

### 1. Download AV-HuBERT Model (MANUAL - Most Important!)

**Why manual?** The model (~400MB) requires you to visit the official site and accept terms.

**Steps:**
1. Visit: http://facebookresearch.github.io/av_hubert
2. Scroll to "Large-scale English model" section
3. Download **large_vox_iter5.pt** (recommended) or **base_vox_iter5.pt**
4. Keep this file - you'll upload it to EC2 in Step 2

**Direct link** (if available):
- Try: https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/large_vox_iter5.pt
- Or browse: http://facebookresearch.github.io/av_hubert

**Time estimate:** 5-10 minutes (depends on your internet speed)

---

### 2. Launch EC2 GPU Instance

**Instance type:** g4dn.xlarge (or any g6 instance you have access to)

**Quick Launch via AWS Console:**

1. Go to EC2 ‚Üí Launch Instance
2. **Name:** gorggle-avhubert
3. **AMI:** Ubuntu Server 22.04 LTS
4. **Instance type:** g4dn.xlarge
5. **Key pair:** Select or create new key pair
6. **Network settings:**
   - VPC: Same as your Lambdas (or default)
   - Auto-assign public IP: Enable
   - Security group: Create new or use existing
     - SSH (22): Your IP
     - Custom TCP (8000): Lambda security group or VPC CIDR
7. **Storage:** 50 GB gp3
8. **Launch instance**

**Time estimate:** 5 minutes

---

### 3. Deploy AV-HuBERT to EC2

**SSH into instance:**
```bash
ssh -i your-key.pem ubuntu@<ec2-public-ip>
```

**Run automated setup:**
```bash
# Clone repository
git clone https://github.com/gordowuu/GORGGLES2.git
cd GORGGLES2/avhubert

# Run setup script (installs everything)
sudo bash setup_ec2.sh
```

**This installs:**
- Miniconda + conda environment
- PyTorch with CUDA
- fairseq framework
- All Python dependencies (fastapi, dlib, opencv, etc.)

**Time estimate:** 10 minutes

---

### 4. Download Model Files

**On EC2, run:**
```bash
cd /home/ubuntu/GORGGLES2/avhubert
bash download_models.sh
```

**This downloads:**
- dlib face detector (10MB)
- dlib landmark predictor (100MB)
- mean_face.npy for mouth alignment (1KB)

**Then upload the AV-HuBERT model you downloaded in Step 1:**
```bash
# On your local machine
scp -i your-key.pem large_vox_iter5.pt ubuntu@<ec2-ip>:/tmp/

# On EC2
sudo mv /tmp/large_vox_iter5.pt /opt/avhubert/model.pt
```

**Verify all files:**
```bash
ls -lh /opt/avhubert/
# Should show: model.pt, *.dat files, mean_face.npy
```

**Time estimate:** 5 minutes

---

### 5. Start the Server

**Setup systemd service:**
```bash
sudo nano /etc/systemd/system/avhubert.service
```

**Paste this config:**
```ini
[Unit]
Description=AV-HuBERT Inference Server
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/opt/avhubert
Environment="PATH=/opt/avhubert/miniconda/envs/avhubert/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
Environment="AVHUBERT_MODEL_PATH=/opt/avhubert/model.pt"
Environment="FACE_DETECTOR_PATH=/opt/avhubert/mmod_human_face_detector.dat"
Environment="LANDMARK_PREDICTOR_PATH=/opt/avhubert/shape_predictor_68_face_landmarks.dat"
Environment="MEAN_FACE_PATH=/opt/avhubert/mean_face.npy"
Environment="AWS_REGION=us-east-1"
ExecStart=/opt/avhubert/miniconda/envs/avhubert/bin/python /home/ubuntu/GORGGLES2/avhubert/server.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

**Save and start:**
```bash
sudo systemctl daemon-reload
sudo systemctl enable avhubert
sudo systemctl start avhubert
sudo systemctl status avhubert
```

**Check logs:**
```bash
sudo journalctl -u avhubert -f
```

Look for:
```
INFO: AV-HuBERT model loaded successfully on cuda
INFO: Face detection models loaded successfully
INFO: Uvicorn running on http://0.0.0.0:8000
```

**Test:**
```bash
curl http://localhost:8000/health
```

**Time estimate:** 5 minutes

---

### 6. Update Lambda Environment Variable

**Get EC2 private IP:**
```bash
# On EC2
hostname -I
# Or in AWS console: EC2 ‚Üí Instances ‚Üí Private IPv4
```

**Update Lambda:**
1. Go to AWS Lambda Console
2. Find `gorggle-dev-invoke_lipreading`
3. Configuration ‚Üí Environment variables
4. Edit `AVHUBERT_ENDPOINT`:
   ```
   http://<ec2-PRIVATE-ip>:8000
   ```
5. Save

**Time estimate:** 2 minutes

---

### 7. Test End-to-End

**Upload test video:**
```bash
aws s3 cp test_video.mp4 s3://gorggle-dev-uploads/test_video.mp4 --profile gorggle-admin
```

**Monitor:**
1. AWS Step Functions console ‚Üí Executions
2. Watch pipeline progress
3. Check CloudWatch Logs for each Lambda

**Get results:**
```bash
# Replace with your job ID from Step Functions
curl https://y9m2193c2i.execute-api.us-east-1.amazonaws.com/results/{jobId}
```

**Time estimate:** Time depends on video length (expect ~2x video duration)

---

## üìä Total Time Estimate

| Step | Time | Difficulty |
|------|------|------------|
| 1. Download model | 5-10 min | Easy |
| 2. Launch EC2 | 5 min | Easy |
| 3. Setup EC2 | 10 min | Easy (automated) |
| 4. Download files | 5 min | Easy |
| 5. Start server | 5 min | Easy |
| 6. Update Lambda | 2 min | Easy |
| 7. Test | 10-20 min | Medium |
| **TOTAL** | **42-57 min** | **Easy** |

---

## üîç Verification Checklist

Before testing, verify:

- [ ] EC2 instance is running
- [ ] Security group allows port 8000 from Lambda
- [ ] All model files exist in `/opt/avhubert/`:
  - [ ] model.pt (~400MB)
  - [ ] mmod_human_face_detector.dat (~10MB)
  - [ ] shape_predictor_68_face_landmarks.dat (~100MB)
  - [ ] mean_face.npy (~1KB)
- [ ] Server is running: `sudo systemctl status avhubert`
- [ ] Health check works: `curl http://localhost:8000/health`
- [ ] Lambda env var updated with EC2 private IP
- [ ] S3 upload bucket exists: `gorggle-dev-uploads`

---

## üö® Important Notes

### License Restriction
**AV-HuBERT is NON-COMMERCIAL RESEARCH ONLY.** If Gorggle is for commercial use:
- Contact Meta Platforms for licensing
- Or find alternative models (e.g., Wav2Vec 2.0, Whisper with video)

### Cost Awareness
**g4dn.xlarge costs:**
- On-Demand: ~$0.526/hour (~$378/month if always on)
- Spot Instance: ~$0.16/hour (~$115/month) - 70% savings

**Recommendation:** Use Spot Instances or stop when not in use.

### Performance
- **Processing speed:** ~2x video duration (10-min video = ~20 min processing)
- **Bottleneck:** Face detection + mouth ROI extraction (most time-consuming)
- **Optimization:** Can batch frames for faster inference

---

## üìö Documentation References

- **Quick Start:** `avhubert/QUICKSTART.md` (30-min guide)
- **Full README:** `avhubert/README.md` (comprehensive docs)
- **Architecture:** `ARCHITECTURE.md` (technical deep dive)
- **Official AV-HuBERT:** https://github.com/facebookresearch/av_hubert
- **Model Downloads:** http://facebookresearch.github.io/av_hubert

---

## üÜò Troubleshooting

### Server won't start
```bash
# Check logs
sudo journalctl -u avhubert -f

# Test manually
source /opt/avhubert/miniconda/bin/activate avhubert
cd /home/ubuntu/GORGGLES2/avhubert
python server.py
```

### CUDA errors
```bash
nvidia-smi  # Check GPU
python -c "import torch; print(torch.cuda.is_available())"
```

### Face detection fails
```bash
ls -lh /opt/avhubert/*.dat  # Verify dlib files
python -c "import dlib; print('OK')"
```

### Out of memory
- Use AV-HuBERT Base instead of Large
- Reduce frame rate in `extract_media` Lambda
- Upgrade to g4dn.2xlarge

---

## ‚úÖ Next Steps After Deployment

1. **Monitor performance:** `watch -n 1 nvidia-smi`
2. **Check costs:** AWS Cost Explorer ‚Üí EC2 GPU instances
3. **Optimize:** Consider using Spot Instances
4. **Scale:** Add more EC2 instances behind load balancer if needed
5. **Package Lambda dependencies:** FFmpeg layer + requests library

---

## üéØ What Makes This Implementation Correct

Compared to the placeholder code, we now have:

‚úÖ **Proper mouth ROI extraction** (96x96, not 224x224 full frames)
‚úÖ **Face alignment** using mean_face.npy template
‚úÖ **dlib face detection** with 68 landmark points
‚úÖ **Mouth-specific cropping** (landmarks 48-68)
‚úÖ **Official preprocessing pipeline** matching AV-HuBERT paper
‚úÖ **All required model files** documented and downloadable
‚úÖ **Automated setup** reducing manual steps
‚úÖ **Production-ready systemd service** with auto-restart

This matches the official AV-HuBERT implementation and will produce accurate lip reading results.

---

**Questions?** Check `avhubert/README.md` or open an issue at:
https://github.com/gordowuu/GORGGLES2/issues
